# -*- coding: utf-8 -*-
"""Untitled31.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XDDX6k2Eo4Mv_1mU140bBoAkJ0NgMwzl
"""

import cv2
import torch

# Load YOLOv7 model
model = torch.hub.load('ultralytics/yolov5:v6.0', 'yolov5s', pretrained=True).autoshape()

# Input and output video paths
input_video_path = 'test_1.mp4'
output_video_path = 'output_video_2.avi'

# Open the input video file
cap = cv2.VideoCapture(input_video_path)

# Get video properties
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Define the codec and create VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can change the codec as needed
out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

# Initialize a variable to store the total count
total_people_count = 0

while True:
    # Read a frame from the video
    ret, frame = cap.read()

    if not ret:
        break

    # Perform inference
    results = model(frame)

    # Draw bounding boxes on the frame
    frame_with_boxes = results.render()[0]

    # Count the number of people detected
    num_people = (results.pred[0][:, -1] == 0).sum().item()

    # Increment the total count
    total_people_count += num_people

    # Display the total number of people using cv2.putText
    cv2.putText(frame_with_boxes, f'Total People: {num_people}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

    # Write the frame with bounding boxes to the output video
    out.write(frame_with_boxes)

    # Display the frame with bounding boxes (optional)
    #cv2.imshow('YOLOv7 Person Detection', frame_with_boxes)

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release resources
cap.release()
out.release()
cv2.destroyAllWindows()